{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step [1]: Prepare libraries and data\n",
    "### [1.1] Include important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import heapq  \n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "punctuation = punctuation + '\\n'\n",
    "from nltk.stem.isri import ISRIStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import RidgeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.2] Text categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['Economy & Business', 'Diverse News', 'Politic', 'Sport', 'Technology']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.3] Building the summerizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_summarizer(input_text, number_of_sentence):\n",
    "    stopWords = set(nltk.corpus.stopwords.words(\"arabic\") + nltk.corpus.stopwords.words(\"english\"))\n",
    "    word_frequencies = {}  \n",
    "    for word in nltk.word_tokenize(input_text):  \n",
    "        if word not in stopWords:\n",
    "            if word not in punctuation:\n",
    "                if word not in word_frequencies.keys():\n",
    "                    word_frequencies[word] = 1\n",
    "                else:\n",
    "                    word_frequencies[word] += 1\n",
    "\n",
    "    maximum_frequncy = max(word_frequencies.values())\n",
    "\n",
    "    for word in word_frequencies.keys():  \n",
    "        word_frequencies[word] = (word_frequencies[word]/maximum_frequncy)\n",
    "\n",
    "    sentence_list = nltk.sent_tokenize(input_text)\n",
    "    sentence_scores = {}  \n",
    "    for sent in sentence_list:  \n",
    "        for word in nltk.word_tokenize(sent.lower()):\n",
    "            if word in word_frequencies.keys():\n",
    "                if len(sent.split(' ')) < 30:\n",
    "                    if sent not in sentence_scores.keys():\n",
    "                        sentence_scores[sent] = word_frequencies[word]\n",
    "                    else:\n",
    "                        sentence_scores[sent] += word_frequencies[word]\n",
    "\n",
    "    summary_sentences = heapq.nlargest(number_of_sentence, sentence_scores, key=sentence_scores.get)\n",
    "\n",
    "    summary = ' '.join(summary_sentences)  \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.4] Reading dataset file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>148</td>\n",
       "      <td>bennett play takes theatre prizes the history ...</td>\n",
       "      <td>diverse news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>1117</td>\n",
       "      <td>stormy year for property insurers a string of ...</td>\n",
       "      <td>economy &amp; business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>343</td>\n",
       "      <td>web photo storage market hots up an increasing...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>1652</td>\n",
       "      <td>german bidder in talks with lse deutsche boers...</td>\n",
       "      <td>economy &amp; business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>707</td>\n",
       "      <td>ireland 21-19 argentina an injury-time dropped...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>1254</td>\n",
       "      <td>chris evans back on the market broadcaster chr...</td>\n",
       "      <td>diverse news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>303</td>\n",
       "      <td>quiksilver moves for rossignol shares of skis ...</td>\n",
       "      <td>economy &amp; business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>1937</td>\n",
       "      <td>more power to the people says hp the digital r...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>1632</td>\n",
       "      <td>elton plays paris charity concert sir elton jo...</td>\n",
       "      <td>diverse news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>1054</td>\n",
       "      <td>black sabbath top rock album poll black sabbat...</td>\n",
       "      <td>diverse news</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ArticleId                                               Text  \\\n",
       "447         148  bennett play takes theatre prizes the history ...   \n",
       "1175       1117  stormy year for property insurers a string of ...   \n",
       "493         343  web photo storage market hots up an increasing...   \n",
       "871        1652  german bidder in talks with lse deutsche boers...   \n",
       "14          707  ireland 21-19 argentina an injury-time dropped...   \n",
       "330        1254  chris evans back on the market broadcaster chr...   \n",
       "147         303  quiksilver moves for rossignol shares of skis ...   \n",
       "1397       1937  more power to the people says hp the digital r...   \n",
       "269        1632  elton plays paris charity concert sir elton jo...   \n",
       "1340       1054  black sabbath top rock album poll black sabbat...   \n",
       "\n",
       "                Category  \n",
       "447         diverse news  \n",
       "1175  economy & business  \n",
       "493                 tech  \n",
       "871   economy & business  \n",
       "14                 sport  \n",
       "330         diverse news  \n",
       "147   economy & business  \n",
       "1397                tech  \n",
       "269         diverse news  \n",
       "1340        diverse news  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_data = pd.read_csv(r\"dataset/bbc_news_dataset.csv\")\n",
    "en_data = en_data.replace(\"entertainment\", \"diverse news\")\n",
    "en_data = en_data.replace(\"business\", \"economy & business\")\n",
    "\n",
    "ar_data = pd.read_csv(r\"dataset/arabic_dataset.csv\")\n",
    "ar_data = ar_data.replace(\"diverse\", \"diverse news\")\n",
    "ar_data = ar_data.replace(\"culture\", \"diverse news\")\n",
    "ar_data = ar_data.replace(\"politic\", \"politics\")\n",
    "ar_data = ar_data.replace(\"technology\", \"tech\")\n",
    "ar_data = ar_data.replace(\"economy\", \"economy & business\")\n",
    "ar_data = ar_data.replace(\"internationalNews\", \"politics\")\n",
    "ar_data = ar_data[~ar_data['type'].str.contains('localnews')]\n",
    "ar_data = ar_data[~ar_data['type'].str.contains('society')]\n",
    "en_data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>122</td>\n",
       "      <td>\\n تواصل قناة الحوار التونسي بث برنامج الالعاب...</td>\n",
       "      <td>diverse news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>259</td>\n",
       "      <td>\\nحجزت وحدات الحرس الوطني بمدنين هذه الليلة نح...</td>\n",
       "      <td>economy &amp; business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4428</th>\n",
       "      <td>48</td>\n",
       "      <td>\\nقررت هيئة المحلفين بمحكمة سان خوسيه الفيدرال...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2419</th>\n",
       "      <td>237</td>\n",
       "      <td>\\nحل رئيس الحكومة يوسف الشاهد اليوم الاربعاء ب...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>1123</td>\n",
       "      <td>\\nأصدرت هيئة شؤون الأسرى والمحررين ونادي الأسي...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4096</th>\n",
       "      <td>1172</td>\n",
       "      <td>\\nأعلن نادى أتلتيكو مدريد الإسباني اليوم الجمع...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3466</th>\n",
       "      <td>542</td>\n",
       "      <td>\\nبرمجت إدارة النجم الرياضي الساحلي مقابلة دول...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>701</td>\n",
       "      <td>\\nيواجه 6 ملايين أمريكي خطر النزوح وتهجيرهم من...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2463</th>\n",
       "      <td>281</td>\n",
       "      <td>\\nأكّد عضو المكتب الجهوي لحزب الاتحاد الوطني ا...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>214</td>\n",
       "      <td>\\nأعلنت وزير المالية، لمياء الزريبي، ان تمويلا...</td>\n",
       "      <td>economy &amp; business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               text  \\\n",
       "246          122  \\n تواصل قناة الحوار التونسي بث برنامج الالعاب...   \n",
       "858          259  \\nحجزت وحدات الحرس الوطني بمدنين هذه الليلة نح...   \n",
       "4428          48  \\nقررت هيئة المحلفين بمحكمة سان خوسيه الفيدرال...   \n",
       "2419         237  \\nحل رئيس الحكومة يوسف الشاهد اليوم الاربعاء ب...   \n",
       "2050        1123  \\nأصدرت هيئة شؤون الأسرى والمحررين ونادي الأسي...   \n",
       "4096        1172  \\nأعلن نادى أتلتيكو مدريد الإسباني اليوم الجمع...   \n",
       "3466         542  \\nبرمجت إدارة النجم الرياضي الساحلي مقابلة دول...   \n",
       "1628         701  \\nيواجه 6 ملايين أمريكي خطر النزوح وتهجيرهم من...   \n",
       "2463         281  \\nأكّد عضو المكتب الجهوي لحزب الاتحاد الوطني ا...   \n",
       "813          214  \\nأعلنت وزير المالية، لمياء الزريبي، ان تمويلا...   \n",
       "\n",
       "                    type  \n",
       "246         diverse news  \n",
       "858   economy & business  \n",
       "4428                tech  \n",
       "2419            politics  \n",
       "2050            politics  \n",
       "4096               sport  \n",
       "3466               sport  \n",
       "1628            politics  \n",
       "2463            politics  \n",
       "813   economy & business  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step [2]: Data sterilization\n",
    "### [2.1] Delete links:\n",
    "This will remove all links from the text and it's include the following:\n",
    "- Matches http protocols like [**http:// or https://**].\n",
    "- Match optional whitespaces after http protocols.\n",
    "- Optionally matches including the [**www.**] or not.\n",
    "- Optionally matches whitespaces in the links.\n",
    "- Matches 0 or more of one or more word characters followed by a period.\n",
    "- Matches 0 or more of one or more words (or a dash or a space) followed by [**\\\\**].\n",
    "- Any remaining path at the end of the url followed by an optional ending.\n",
    "- Matches ending query params (even with white spaces, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_links(input_text):\n",
    "    pettern  = r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))'''\n",
    "    out_text = re.sub(pettern, ' ', input_text)\n",
    "    return out_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2.2] Fixing word lengthening:\n",
    "Word lengthening occurs when characters are wrongly repeated. English words have a max of two repeated characters like the words [**wood, school**]. Additional characters need to ripped off, otherwise we might add misleading information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_repeated_characters(input_text):\n",
    "    pattern  = r'(.)\\1{2,}'\n",
    "    out_text = re.sub(pattern, r\"\\1\\1\", input_text)\n",
    "    return out_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_letters(input_text):\n",
    "    replace = {\"أ\": \"ا\",\"ة\": \"ه\",\"إ\": \"ا\",\"آ\": \"ا\",\"\": \"\"}\n",
    "    replace = dict((re.escape(k), v) for k, v in replace.items()) \n",
    "    pattern = re.compile(\"|\".join(replace.keys()))\n",
    "    out_text = pattern.sub(lambda m: replace[re.escape(m.group(0))], input_text)\n",
    "    return out_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2.3] Delete bad symbols:\n",
    "This method removes unwanted characters from the text, such as question marks, commas, star, plus ...etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(input_text):\n",
    "    replace = r'[/(){}\\[\\]|@âÂ,;\\?\\'\\\"\\*…؟–’،!&\\+-:؛-]'\n",
    "    out_text = re.sub(replace, \" \", input_text)\n",
    "    words = nltk.word_tokenize(out_text)\n",
    "    words = [word for word in words if word.isalpha()]\n",
    "    out_text = ' '.join(words)\n",
    "    return out_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_vowelization(input_text):\n",
    "    vowelization = re.compile(\"\"\" ّ|َ|ً|ُ|ٌ|ِ|ٍ|ْ|ـ\"\"\", re.VERBOSE)\n",
    "    out_text = re.sub(vowelization, '', input_text)\n",
    "    return out_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2.4] Delete stopwords:\n",
    "Like prepositions and hyphens words. for example [**and, in, or ...etc**]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_stopwords(input_text):\n",
    "    stop_words = set(nltk.corpus.stopwords.words(\"arabic\") + nltk.corpus.stopwords.words(\"english\"))\n",
    "    tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "    tokens = tokenizer.tokenize(input_text)\n",
    "    wnl = nltk.WordNetLemmatizer()\n",
    "    lemmatizedTokens =[wnl.lemmatize(t) for t in tokens]\n",
    "    out_text = [w for w in lemmatizedTokens if not w in stop_words]\n",
    "    out_text = ' '.join(out_text)\n",
    "    return out_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_text(input_text):\n",
    "    st = ISRIStemmer()\n",
    "    tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "    tokens = tokenizer.tokenize(input_text)\n",
    "    out_text = [st.stem(w) for w in tokens]\n",
    "    out_text = ' '.join(out_text)\n",
    "    return out_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2.5] Text prepare:\n",
    "- Applay all previus functions to sterilize the input text.\n",
    "- Convert letters to lowercase to make all words in the text in the same letters sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_prepare(input_text, ar_text):\n",
    "    out_text = delete_links(input_text)\n",
    "    out_text = delete_repeated_characters(out_text)\n",
    "    out_text = clean_text(out_text)\n",
    "    out_text = delete_stopwords(out_text)\n",
    "    if ar_text:\n",
    "        out_text = replace_letters(out_text)\n",
    "        out_text = remove_vowelization(out_text)\n",
    "        out_text = stem_text(out_text)\n",
    "    else:\n",
    "        out_text = out_text.lower()\n",
    "    return out_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>Processed Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>618</td>\n",
       "      <td>rivals of the £400 apple... the mac mini is th...</td>\n",
       "      <td>tech</td>\n",
       "      <td>rival apple mac mini cheapest apple computer e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>1648</td>\n",
       "      <td>game makers get xbox 2 sneak peek microsoft ha...</td>\n",
       "      <td>tech</td>\n",
       "      <td>game maker get xbox sneak peek microsoft ha gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>1896</td>\n",
       "      <td>parmalat to return to stockmarket parmalat  th...</td>\n",
       "      <td>economy &amp; business</td>\n",
       "      <td>parmalat return stockmarket parmalat italian d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>1436</td>\n",
       "      <td>banker loses sexism claim a former executive a...</td>\n",
       "      <td>economy &amp; business</td>\n",
       "      <td>banker loses sexism claim former executive lon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>1921</td>\n",
       "      <td>holmes back on form in birmingham double olymp...</td>\n",
       "      <td>sport</td>\n",
       "      <td>holmes back form birmingham double olympic cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>393</td>\n",
       "      <td>robinson answers critics england captain jason...</td>\n",
       "      <td>sport</td>\n",
       "      <td>robinson answer critic england captain jason r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>2193</td>\n",
       "      <td>us duo in first spam conviction a brother and ...</td>\n",
       "      <td>tech</td>\n",
       "      <td>u duo first spam conviction brother sister u c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>420</td>\n",
       "      <td>celtic unhappy over bulgaria date martin o nei...</td>\n",
       "      <td>sport</td>\n",
       "      <td>celtic unhappy bulgaria date martin neill hope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1259</td>\n",
       "      <td>honda wins china copyright ruling japan s hond...</td>\n",
       "      <td>economy &amp; business</td>\n",
       "      <td>honda win china copyright ruling japan honda h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>1013</td>\n",
       "      <td>galloway targets  new labour  mp george gallow...</td>\n",
       "      <td>politics</td>\n",
       "      <td>galloway target new labour mp george galloway ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ArticleId                                               Text  \\\n",
       "106         618  rivals of the £400 apple... the mac mini is th...   \n",
       "603        1648  game makers get xbox 2 sneak peek microsoft ha...   \n",
       "590        1896  parmalat to return to stockmarket parmalat  th...   \n",
       "1398       1436  banker loses sexism claim a former executive a...   \n",
       "476        1921  holmes back on form in birmingham double olymp...   \n",
       "621         393  robinson answers critics england captain jason...   \n",
       "1302       2193  us duo in first spam conviction a brother and ...   \n",
       "252         420  celtic unhappy over bulgaria date martin o nei...   \n",
       "100        1259  honda wins china copyright ruling japan s hond...   \n",
       "805        1013  galloway targets  new labour  mp george gallow...   \n",
       "\n",
       "                Category                                     Processed Text  \n",
       "106                 tech  rival apple mac mini cheapest apple computer e...  \n",
       "603                 tech  game maker get xbox sneak peek microsoft ha gi...  \n",
       "590   economy & business  parmalat return stockmarket parmalat italian d...  \n",
       "1398  economy & business  banker loses sexism claim former executive lon...  \n",
       "476                sport  holmes back form birmingham double olympic cha...  \n",
       "621                sport  robinson answer critic england captain jason r...  \n",
       "1302                tech  u duo first spam conviction brother sister u c...  \n",
       "252                sport  celtic unhappy bulgaria date martin neill hope...  \n",
       "100   economy & business  honda win china copyright ruling japan honda h...  \n",
       "805             politics  galloway target new labour mp george galloway ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_data['Processed Text'] = en_data['Text'].apply(text_prepare, args=(False,))\n",
    "ar_data['Processed Text'] = ar_data['text'].apply(text_prepare, args=(True,))\n",
    "en_data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>Processed Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3939</th>\n",
       "      <td>1015</td>\n",
       "      <td>\\nتجرى اليوم مقابلات  الجولة الختامية من المرح...</td>\n",
       "      <td>sport</td>\n",
       "      <td>جرى اليوم قبل جول ختم رحل ولى بطل ربط حرف لكر ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3591</th>\n",
       "      <td>667</td>\n",
       "      <td>\\nقرر الإطار الفني للنادي الإفريقي التعويل على...</td>\n",
       "      <td>sport</td>\n",
       "      <td>قرر اطر فني ندي فرق عول شكل سسي واج فتح ربط ال...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4410</th>\n",
       "      <td>30</td>\n",
       "      <td>\\nبدأ موقع \"ويكيليكس\"، اليوم الثلاثاء، في نشر ...</td>\n",
       "      <td>tech</td>\n",
       "      <td>بدا وقع ويكيليكس اليوم ثلاثاء نشر لسل وثق سرب ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>449</td>\n",
       "      <td>\\nتفجر جدل في الجزائر بسبب ملصق إشهاري فيه صور...</td>\n",
       "      <td>politics</td>\n",
       "      <td>فجر جدل جزر سبب لصق شهر صور شخص يدع نخب شرع نه...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3840</th>\n",
       "      <td>916</td>\n",
       "      <td>\\nتحتضن القاعة الأولمبية بسوسة اليوم مقابلة كل...</td>\n",
       "      <td>sport</td>\n",
       "      <td>حضن قعه لمب بسس اليوم قبل كلاسيكو بطل وطن لكر ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3734</th>\n",
       "      <td>810</td>\n",
       "      <td>\\nخاض المنتخب التونسي للسيدات صباح اليوم اخر ح...</td>\n",
       "      <td>sport</td>\n",
       "      <td>خاض نخب ونس سيد اليوم اخر حصه درب سفر ليل عصم ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>158</td>\n",
       "      <td>\\nدعا الناطق باسم القيادة العامة للقوات المسلح...</td>\n",
       "      <td>politics</td>\n",
       "      <td>دعا نطق بسم قيد عمه قوت سلح ليب عقد حمد سمر وط...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3238</th>\n",
       "      <td>314</td>\n",
       "      <td>\\nاقتحم أحد المشجعين في خطوة مفاجأة أرضية ملعب...</td>\n",
       "      <td>sport</td>\n",
       "      <td>قحم شجع خطه فجا ارض لعب ثنء برا كره قدم وقم عر...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3926</th>\n",
       "      <td>1002</td>\n",
       "      <td>\\nأكد المنسق الإعلامي للترجي الجرجيسي محمد الز...</td>\n",
       "      <td>sport</td>\n",
       "      <td>اكد نسق علم ترج جرجيس حمد زبل صرح رسل جوهر جهه...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4118</th>\n",
       "      <td>1194</td>\n",
       "      <td>\\nأعلنت الجامعة التونسية لكرة القدم أنها قررت ...</td>\n",
       "      <td>sport</td>\n",
       "      <td>اعل جمع ونس لكر قدم انه قرر قضا لفز وطن سبب خل...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               text      type  \\\n",
       "3939        1015  \\nتجرى اليوم مقابلات  الجولة الختامية من المرح...     sport   \n",
       "3591         667  \\nقرر الإطار الفني للنادي الإفريقي التعويل على...     sport   \n",
       "4410          30  \\nبدأ موقع \"ويكيليكس\"، اليوم الثلاثاء، في نشر ...      tech   \n",
       "1376         449  \\nتفجر جدل في الجزائر بسبب ملصق إشهاري فيه صور...  politics   \n",
       "3840         916  \\nتحتضن القاعة الأولمبية بسوسة اليوم مقابلة كل...     sport   \n",
       "3734         810  \\nخاض المنتخب التونسي للسيدات صباح اليوم اخر ح...     sport   \n",
       "1085         158  \\nدعا الناطق باسم القيادة العامة للقوات المسلح...  politics   \n",
       "3238         314  \\nاقتحم أحد المشجعين في خطوة مفاجأة أرضية ملعب...     sport   \n",
       "3926        1002  \\nأكد المنسق الإعلامي للترجي الجرجيسي محمد الز...     sport   \n",
       "4118        1194  \\nأعلنت الجامعة التونسية لكرة القدم أنها قررت ...     sport   \n",
       "\n",
       "                                         Processed Text  \n",
       "3939  جرى اليوم قبل جول ختم رحل ولى بطل ربط حرف لكر ...  \n",
       "3591  قرر اطر فني ندي فرق عول شكل سسي واج فتح ربط ال...  \n",
       "4410  بدا وقع ويكيليكس اليوم ثلاثاء نشر لسل وثق سرب ...  \n",
       "1376  فجر جدل جزر سبب لصق شهر صور شخص يدع نخب شرع نه...  \n",
       "3840  حضن قعه لمب بسس اليوم قبل كلاسيكو بطل وطن لكر ...  \n",
       "3734  خاض نخب ونس سيد اليوم اخر حصه درب سفر ليل عصم ...  \n",
       "1085  دعا نطق بسم قيد عمه قوت سلح ليب عقد حمد سمر وط...  \n",
       "3238  قحم شجع خطه فجا ارض لعب ثنء برا كره قدم وقم عر...  \n",
       "3926  اكد نسق علم ترج جرجيس حمد زبل صرح رسل جوهر جهه...  \n",
       "4118  اعل جمع ونس لكر قدم انه قرر قضا لفز وطن سبب خل...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step [3]: Text Splitting and vectorizing\n",
    "### [3.1] Label encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>Processed Text</th>\n",
       "      <th>Category Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>563</td>\n",
       "      <td>cable offers video-on-demand cable firms ntl a...</td>\n",
       "      <td>tech</td>\n",
       "      <td>cable offer video demand cable firm ntl telewe...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>1903</td>\n",
       "      <td>labour trio  had vote-rig factory  three labou...</td>\n",
       "      <td>politics</td>\n",
       "      <td>labour trio vote rig factory three labour coun...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>824</td>\n",
       "      <td>rank  set to sell off film unit  leisure group...</td>\n",
       "      <td>economy &amp; business</td>\n",
       "      <td>rank set sell film unit leisure group rank cou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>1369</td>\n",
       "      <td>no uk apology  for colonial past the days of b...</td>\n",
       "      <td>politics</td>\n",
       "      <td>uk apology colonial past day britain apologise...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>1292</td>\n",
       "      <td>man utd stroll to cup win wayne rooney made a ...</td>\n",
       "      <td>sport</td>\n",
       "      <td>man utd stroll cup win wayne rooney made winni...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>441</td>\n",
       "      <td>lasers help bridge network gaps an indian tele...</td>\n",
       "      <td>tech</td>\n",
       "      <td>laser help bridge network gap indian telecommu...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>705</td>\n",
       "      <td>newest eu members underpin growth the european...</td>\n",
       "      <td>economy &amp; business</td>\n",
       "      <td>newest eu member underpin growth european unio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>39</td>\n",
       "      <td>debate needed  on donations cap a cap on donat...</td>\n",
       "      <td>politics</td>\n",
       "      <td>debate needed donation cap cap donation politi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>254</td>\n",
       "      <td>first look at playstation 3 chip some details ...</td>\n",
       "      <td>tech</td>\n",
       "      <td>first look playstation chip detail chip inside...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>1846</td>\n",
       "      <td>rescue hope for borussia dortmund shares in st...</td>\n",
       "      <td>economy &amp; business</td>\n",
       "      <td>rescue hope borussia dortmund share struggling...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ArticleId                                               Text  \\\n",
       "489         563  cable offers video-on-demand cable firms ntl a...   \n",
       "866        1903  labour trio  had vote-rig factory  three labou...   \n",
       "1150        824  rank  set to sell off film unit  leisure group...   \n",
       "1298       1369  no uk apology  for colonial past the days of b...   \n",
       "794        1292  man utd stroll to cup win wayne rooney made a ...   \n",
       "481         441  lasers help bridge network gaps an indian tele...   \n",
       "979         705  newest eu members underpin growth the european...   \n",
       "123          39  debate needed  on donations cap a cap on donat...   \n",
       "397         254  first look at playstation 3 chip some details ...   \n",
       "585        1846  rescue hope for borussia dortmund shares in st...   \n",
       "\n",
       "                Category                                     Processed Text  \\\n",
       "489                 tech  cable offer video demand cable firm ntl telewe...   \n",
       "866             politics  labour trio vote rig factory three labour coun...   \n",
       "1150  economy & business  rank set sell film unit leisure group rank cou...   \n",
       "1298            politics  uk apology colonial past day britain apologise...   \n",
       "794                sport  man utd stroll cup win wayne rooney made winni...   \n",
       "481                 tech  laser help bridge network gap indian telecommu...   \n",
       "979   economy & business  newest eu member underpin growth european unio...   \n",
       "123             politics  debate needed donation cap cap donation politi...   \n",
       "397                 tech  first look playstation chip detail chip inside...   \n",
       "585   economy & business  rescue hope borussia dortmund share struggling...   \n",
       "\n",
       "      Category Encoded  \n",
       "489                  4  \n",
       "866                  2  \n",
       "1150                 1  \n",
       "1298                 2  \n",
       "794                  3  \n",
       "481                  4  \n",
       "979                  1  \n",
       "123                  2  \n",
       "397                  4  \n",
       "585                  1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_label_encoder = LabelEncoder()\n",
    "en_data['Category Encoded'] = en_label_encoder.fit_transform(en_data['Category'])\n",
    "\n",
    "ar_label_encoder = LabelEncoder()\n",
    "ar_data['Category Encoded'] = ar_label_encoder.fit_transform(ar_data['type'])\n",
    "ar_data['Category Encoded'] = ar_data['Category Encoded'].replace(1, 0)\n",
    "ar_data['Category Encoded'] = ar_data['Category Encoded'].replace(0, 1)\n",
    "\n",
    "en_data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>Processed Text</th>\n",
       "      <th>Category Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1159</th>\n",
       "      <td>232</td>\n",
       "      <td>\\nجد مساء الأحد تفجير انتحاري استهدف مركزاً لل...</td>\n",
       "      <td>politics</td>\n",
       "      <td>جد احد فجر نحر هدف شرط قسنط شرق جزر سفر سقط عد...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3629</th>\n",
       "      <td>705</td>\n",
       "      <td>\\nتوصلت الجامعة التونسية لكرة القدم إلى اتفاق ...</td>\n",
       "      <td>sport</td>\n",
       "      <td>وصل جمع ونس لكر قدم تفق لعب رنس ديل برن لعب فر...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2813</th>\n",
       "      <td>631</td>\n",
       "      <td>\\nأعلنت النائب عن نداء تونس ليلى الشتاوي اليوم...</td>\n",
       "      <td>politics</td>\n",
       "      <td>اعل نئب ندء ونس يلى شتو اليوم ربعاء جمد عضي حز...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2860</th>\n",
       "      <td>678</td>\n",
       "      <td>\\nاعتبر النائب بمجلس نواب الشعب، عبد العزيز ال...</td>\n",
       "      <td>politics</td>\n",
       "      <td>عبر نئب جلس نوب شعب عبد عزز قطي زير ادا رفق عد...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893</th>\n",
       "      <td>966</td>\n",
       "      <td>\\nقالت شبكة (سي.إن.إن) الإخبارية الأميركية، أم...</td>\n",
       "      <td>politics</td>\n",
       "      <td>قلت شبك سي خبر امر انه انه مثل كوميد كثي جرف و...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>209</td>\n",
       "      <td>\\nخفضت وكالة \"فيتش\" للتصنيف الائتماني أمس الجم...</td>\n",
       "      <td>economy &amp; business</td>\n",
       "      <td>خفض وكل يتش صنف ئما جمع علم ونس درج وحد سلب يج...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>86</td>\n",
       "      <td>\\nنشرت صحيفة ديلي ميل البريطانية صورة انفجار ح...</td>\n",
       "      <td>diverse news</td>\n",
       "      <td>نشر صحف ديل ميل بريطانيه صور فجر حفل جسرلامبيث...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712</th>\n",
       "      <td>530</td>\n",
       "      <td>\\nنشرت حركة النهضة اليوم الخميس بلاغا توضيحيا ...</td>\n",
       "      <td>politics</td>\n",
       "      <td>نشر حرك نهض اليوم خمس بلغ وضح حول قرر رئس حرك ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\\nأشرف رئيس الجمهورية الباجي قايد السبسي اليوم...</td>\n",
       "      <td>diverse news</td>\n",
       "      <td>شرف رئس جمهور بجي قيد سبس اليوم قصر قرطاج وكب ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2449</th>\n",
       "      <td>267</td>\n",
       "      <td>\\nقرّرت اللجنة الوطنية للنظام لحركة نداء تونس ...</td>\n",
       "      <td>politics</td>\n",
       "      <td>لجن وطن نظم لحر ندء ونس جمد عضي يلى حزب تبع جم...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               text  \\\n",
       "1159         232  \\nجد مساء الأحد تفجير انتحاري استهدف مركزاً لل...   \n",
       "3629         705  \\nتوصلت الجامعة التونسية لكرة القدم إلى اتفاق ...   \n",
       "2813         631  \\nأعلنت النائب عن نداء تونس ليلى الشتاوي اليوم...   \n",
       "2860         678  \\nاعتبر النائب بمجلس نواب الشعب، عبد العزيز ال...   \n",
       "1893         966  \\nقالت شبكة (سي.إن.إن) الإخبارية الأميركية، أم...   \n",
       "808          209  \\nخفضت وكالة \"فيتش\" للتصنيف الائتماني أمس الجم...   \n",
       "210           86  \\nنشرت صحيفة ديلي ميل البريطانية صورة انفجار ح...   \n",
       "2712         530  \\nنشرت حركة النهضة اليوم الخميس بلاغا توضيحيا ...   \n",
       "0              0  \\nأشرف رئيس الجمهورية الباجي قايد السبسي اليوم...   \n",
       "2449         267  \\nقرّرت اللجنة الوطنية للنظام لحركة نداء تونس ...   \n",
       "\n",
       "                    type                                     Processed Text  \\\n",
       "1159            politics  جد احد فجر نحر هدف شرط قسنط شرق جزر سفر سقط عد...   \n",
       "3629               sport  وصل جمع ونس لكر قدم تفق لعب رنس ديل برن لعب فر...   \n",
       "2813            politics  اعل نئب ندء ونس يلى شتو اليوم ربعاء جمد عضي حز...   \n",
       "2860            politics  عبر نئب جلس نوب شعب عبد عزز قطي زير ادا رفق عد...   \n",
       "1893            politics  قلت شبك سي خبر امر انه انه مثل كوميد كثي جرف و...   \n",
       "808   economy & business  خفض وكل يتش صنف ئما جمع علم ونس درج وحد سلب يج...   \n",
       "210         diverse news  نشر صحف ديل ميل بريطانيه صور فجر حفل جسرلامبيث...   \n",
       "2712            politics  نشر حرك نهض اليوم خمس بلغ وضح حول قرر رئس حرك ...   \n",
       "0           diverse news  شرف رئس جمهور بجي قيد سبس اليوم قصر قرطاج وكب ...   \n",
       "2449            politics  لجن وطن نظم لحر ندء ونس جمد عضي يلى حزب تبع جم...   \n",
       "\n",
       "      Category Encoded  \n",
       "1159                 2  \n",
       "3629                 3  \n",
       "2813                 2  \n",
       "2860                 2  \n",
       "1893                 2  \n",
       "808                  1  \n",
       "210                  1  \n",
       "2712                 2  \n",
       "0                    1  \n",
       "2449                 2  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3.2] Splitting the data to train and text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_X_train, en_X_test, en_y_train, en_y_test = train_test_split(en_data['Processed Text'], en_data['Category Encoded'], test_size=0.2, random_state=0)\n",
    "ar_X_train, ar_X_test, ar_y_train, ar_y_test = train_test_split(ar_data['Processed Text'], ar_data['Category Encoded'], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3.3] TF-IDF vectorizer:\n",
    "The second approach extends the bag-of-words framework by taking into account total frequencies of words in the corpora. It helps to penalize too frequent words and provide better features space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_features(X_train, X_test, ngram_range):\n",
    "    tfidf_vectorizer = TfidfVectorizer(min_df=2, max_df=0.5, ngram_range=(1, ngram_range))\n",
    "    X_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "    X_test = tfidf_vectorizer.transform(X_test)\n",
    "    return X_train, X_test, tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_features_train, en_features_test, vectorizer_en = tfidf_features(en_X_train, en_X_test, 2)\n",
    "pickle.dump(vectorizer_en, open('tfidf_en.pkl', 'wb'), protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_features_train, ar_features_test, vectorizer_ar = tfidf_features(ar_X_train, ar_X_test, 2)\n",
    "pickle.dump(vectorizer_ar, open('tfidf_ar.pkl', 'wb'), protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3.4] Fit model:\n",
    "This function used to generate a model based on it's name then train that model and calculate it's accuracy on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model_name, ar_text=False):\n",
    "    if model_name == 'ridge_model':\n",
    "        model_name = RidgeClassifier()\n",
    "    elif model_name == 'random_forest_model':\n",
    "        model_name = RandomForestClassifier()\n",
    "    elif model_name == 'logistic_regression_model':\n",
    "        model_name = LogisticRegression()\n",
    "    elif model_name == 'kneighbors_model':\n",
    "        model_name = KNeighborsClassifier()\n",
    "    elif model_name == 'decision_tree_model':\n",
    "        model_name = DecisionTreeClassifier()\n",
    "    elif model_name == 'gaussian_nb_model':\n",
    "        model_name = GaussianNB()\n",
    "    if ar_text:\n",
    "        model_name.fit(ar_features_train.toarray(), ar_y_train)\n",
    "        model_predictions = model_name.predict(ar_features_test.toarray())\n",
    "        print(\"Accuracy on test: \", accuracy_score(ar_y_test, model_predictions))\n",
    "    else:\n",
    "        model_name.fit(en_features_train.toarray(), en_y_train)\n",
    "        model_predictions = model_name.predict(en_features_test.toarray())\n",
    "        print(\"Accuracy on test: \", accuracy_score(en_y_test, model_predictions))\n",
    "    return model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3.5] Summerize and predict for input text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summerize_category(input_text, statements, model_name, ar_text=False):\n",
    "    summary_text = nltk_summarizer(input_text, statements)\n",
    "    print(\"-------------------------------------------------------------------------------------------------------------------------------\")\n",
    "    print(\"Text summary\")\n",
    "    print(\"-------------------------------------------------------------------------------------------------------------------------------\")\n",
    "    print(summary_text)\n",
    "    print(\"-------------------------------------------------------------------------------------------------------------------------------\")\n",
    "    input_text_arr = [text_prepare(input_text, ar_text)]\n",
    "    if ar_text:\n",
    "        features_train, features_test, vec = tfidf_features(ar_X_train, input_text_arr, 2)\n",
    "    else:\n",
    "        features_train, features_test, vec = tfidf_features(en_X_train, input_text_arr, 2)\n",
    "    text_predection = model_name.predict(features_test.toarray())\n",
    "    print(\"Text category:\", categories[text_predection[0]])\n",
    "    print(\"-------------------------------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [3.3.1] Ridge classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test:  0.9832214765100671\n"
     ]
    }
   ],
   "source": [
    "en_ridge_model = fit_model('ridge_model')\n",
    "pickle.dump(en_ridge_model, open('en_ridge_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [3.3.2] Random forest classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test:  0.9563758389261745\n"
     ]
    }
   ],
   "source": [
    "en_random_forest_model = fit_model('random_forest_model')\n",
    "pickle.dump(en_random_forest_model, open('en_random_forest_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [3.3.3]  Logistic regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test:  0.9899328859060402\n"
     ]
    }
   ],
   "source": [
    "en_logistic_regression_model = fit_model('logistic_regression_model')\n",
    "pickle.dump(en_logistic_regression_model, open('en_logistic_regression_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [3.3.4] K-Neighbors classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test:  0.959731543624161\n"
     ]
    }
   ],
   "source": [
    "en_kneighbors_model = fit_model('kneighbors_model')\n",
    "pickle.dump(en_kneighbors_model, open('en_kneighbors_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [3.3.5] Decision treeClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test:  0.8691275167785235\n"
     ]
    }
   ],
   "source": [
    "en_decision_tree_model = fit_model('decision_tree_model')\n",
    "pickle.dump(en_decision_tree_model, open('en_decision_tree_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [3.3.6] GaussianNB model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test:  0.9463087248322147\n"
     ]
    }
   ],
   "source": [
    "en_gaussian_nb_model = fit_model('gaussian_nb_model')\n",
    "pickle.dump(en_gaussian_nb_model, open('en_gaussian_nb_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step [4]: Test cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = \"The term machine learning was coined in 1959 by Arthur Samuel, an American IBMer and pioneer in the field of\\\n",
    "computer gaming and artificial intelligence.[8][9] A representative book of the machine learning research during the 1960s\\\n",
    "was the Nilsson's book on Learning Machines, dealing mostly with machine learning for pattern classification.[10] Interest\\\n",
    "related to pattern recognition continued into the 1970s, as described by Duda and Hart in 1973.[11] In 1981 a report was given\\\n",
    "on using teaching strategies so that a neural network learns to recognize 40 characters (26 letters, 10 digits, and 4 special\\\n",
    "symbols) from a computer terminal.[12] Tomamom M. Mitchell provided a widely quoted, more formal definition of the algorithms\\\n",
    "studied in the machine learning field: A computer program is said to learn from experience E with respect to some class of\\\n",
    "tasks T and performance measure P if its performance at tasks in T, as measured by P, improves with experience E.\\\n",
    "[13] This definition of the tasks in which machine learning is concerned offers a fundamentally operational definition rather\\\n",
    "than defining the field in cognitive terms. This follows Alan Turing's proposal in his paper Computing Machinery\\\n",
    "and Intelligence, in which the question Can machines think? is replaced with the question Can machines do what we\\\n",
    "(as thinking entities) can do?.[14] Modern day machine learning has two objectives, one is to classify data based on models\\\n",
    "which have been developed, the other purpose is to make predictions for future outcomes based on these model.\\\n",
    "A hypothetical algorithm specific to classifying data may use computer vision of moles coupled with supervised learning\\\n",
    "in order to train it to classify the cancerous moles. Where as, a machine learning algoritihim for stock trading may inform\\\n",
    "the trader of future potential predictions.[15] Artificial intelligence Machine Learning as subfield of AI[16] Part of Machine\\\n",
    "Learning as subfield of AI or part of AI as subfield of Machine Learning[17] As a scientific endeavor, machine learning grew\\\n",
    "out of the quest for artificial intelligence. In the early days of AI as an academic discipline, some researchers were\\\n",
    "interested in having machines learn from data. They attempted to approach the problem with various symbolic methods,\\\n",
    "as well as what was then termed neural networks; these were mostly perceptrons and other models that were later found\\\n",
    "to be reinventions of the generalized linear models of statistics.[18] Probabilistic reasoning was also employed,\\\n",
    "especially in automated medical diagnosis.[19]:488 However, an increasing emphasis on the logical, knowledge-based approach\\\n",
    "caused a rift between AI and machine learning. Probabilistic systems were plagued by theoretical and practical problems\\\n",
    "of data acquisition and representation.[19]:488 By 1980, expert systems had come to dominate AI, and statistics was out of\\\n",
    "favor.[20] Work on symbolic/knowledge-based learning did continue within AI, leading to inductive logic programming,\\\n",
    "but the more statistical line of research was now outside the field of AI proper, in pattern recognition and information\\\n",
    "retrieval.[19]:708–710; 755 Neural networks research had been abandoned by AI and computer science around the same time.\\\n",
    "This line, too, was continued outside the AI/CS field, as connectionism, by researchers from other disciplines including\\\n",
    "Hopfield, Rumelhart and Hinton. Their main success came in the mid-1980s with the reinvention of backpropagation.\\\n",
    "[19]:25 Machine learning (ML), reorganized as a separate field, started to flourish in the 1990s. The field changed its goal\\\n",
    "from achieving artificial intelligence to tackling solvable problems of a practical nature. It shifted focus away from\\\n",
    "the symbolic approaches it had inherited from AI, and toward methods and models borrowed from statistics and probability\\\n",
    "theory.[20] As of 2020, many sources continue to assert that machine learning remains a subfield of AI.[21][22][16] The main\\\n",
    "disagreement is whether all of ML is part of AI, as this would mean that anyone using ML could claim they are using AI.\\\n",
    "Others have the view that not all of ML is part of AI[23][24][25] where only an intelligent subset of ML is part of AI.\\\n",
    "[26] The question to what is the difference between ML and AI is answered by Judea Pearl in The Book of Why.\\\n",
    "[27] Accordingly ML learns and predicts based on passive observations, whereas AI implies an agent interacting with the\\\n",
    "environment to learn and take actions that maximize its chance of successfully achieving its goals.[30]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "Text summary\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "[8][9] A representative book of the machine learning research during the 1960swas the Nilsson's book on Learning Machines, dealing mostly with machine learning for pattern classification. The term machine learning was coined in 1959 by Arthur Samuel, an American IBMer and pioneer in the field ofcomputer gaming and artificial intelligence. [19]:25 Machine learning (ML), reorganized as a separate field, started to flourish in the 1990s. [20] As of 2020, many sources continue to assert that machine learning remains a subfield of AI. Where as, a machine learning algoritihim for stock trading may informthe trader of future potential predictions. [19]:488 However, an increasing emphasis on the logical, knowledge-based approachcaused a rift between AI and machine learning. The field changed its goalfrom achieving artificial intelligence to tackling solvable problems of a practical nature. It shifted focus away fromthe symbolic approaches it had inherited from AI, and toward methods and models borrowed from statistics and probabilitytheory. In the early days of AI as an academic discipline, some researchers wereinterested in having machines learn from data. This follows Alan Turing's proposal in his paper Computing Machineryand Intelligence, in which the question Can machines think?\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "Text category: Technology\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summerize_category(test_1, 10, en_random_forest_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2 = \"Founded on 6 March 1902 as Madrid Football Club, the club has traditionally worn a white home kit since inception. \\\n",
    "The word real is Spanish for \\\"royal\\\" and was bestowed to the club by King Alfonso XIII in 1920 together with the royal crown\\\n",
    "in the emblem. The team has played its home matches in the 81,044-capacity Santiago Bernabéu Stadium in downtown Madrid since\\\n",
    "1947. Unlike most European sporting entities, Real Madrids members (socios) have owned and operated the club throughout its\\\n",
    "history. The club was estimated to be worth €3.8 billion ($4.2 billion) in 2019, and it was the second highest-earning football\\\n",
    "club in the world, with an annual revenue of €757.3 million in 2019.[7][8] The club is one of the most widely supported teams\\\n",
    "in the world.[9] Real Madrid is one of three founding members of La Liga that have never been relegated from the top division\\\n",
    "since its inception in 1929, along with Athletic Bilbao and Barcelona. The club holds many long-standing rivalries,\\\n",
    "most notably El Clásico with Barcelona and El Derbi with Atlético Madrid. Real Madrid established itself as a major force in\\\n",
    "both Spanish and European football during the 1950s, winning five consecutive European Cups and reaching the final seven times.\\\n",
    "This success was replicated in the league, which the club won five times in the space of seven years. This team, which\\\n",
    "consisted of players Alfredo Di Stéfano, Ferenc Puskás, Francisco Gento, and Raymond Kopa, is considered by some in the sport\\\n",
    "to be the greatest team of all time.[10][11][12] In domestic football, the club has won 66 trophies; a record 34 La Liga\\\n",
    "titles, 19 Copa del Rey, 11 Supercopa de España, a Copa Eva Duarte, and a Copa de la Liga.[13] In European and worldwide\\\n",
    "competitions, Real Madrid have won a record 26 trophies; a record 13 European Cup/UEFA Champions League titles, two UEFA Cups\\\n",
    "and four UEFA Super Cups. In international football, they have achieved a record seven club world championships.[note 1] Real\\\n",
    "Madrid was recognised as the FIFA Club of the 20th Century on 11 December 2000 with 42.35% of the vote,[15] and received\\\n",
    "the FIFA Centennial Order of Merit on 20 May 2004.[16] The club was also awarded Best European Club of the 20th Century by the\\\n",
    "IFFHS on 11 May 2010. In June 2017, the team succeeded in becoming the first club to win consecutive Champions League titles, \\\n",
    "then made it three in a row and four in five seasons in May 2018, extending their lead atop the UEFA club rankings. As of 2020,\\\n",
    "Real Madrid are ranked third behind Bayern Munich and Barcelona.[17][18]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "Text summary\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "Founded on 6 March 1902 as Madrid Football Club, the club has traditionally worn a white home kit since inception. [16] The club was also awarded Best European Club of the 20th Century by theIFFHS on 11 May 2010. In international football, they have achieved a record seven club world championships. The word real is Spanish for \"royal\" and was bestowed to the club by King Alfonso XIII in 1920 together with the royal crownin the emblem. [13] In European and worldwidecompetitions, Real Madrid have won a record 26 trophies; a record 13 European Cup/UEFA Champions League titles, two UEFA Cupsand four UEFA Super Cups.\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "Text category: Sport\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summerize_category(test_2, 5, en_ridge_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_3 = \"Born and raised in Queens, New York City, Trump attended Fordham University for two years and received a bachelor's \\\n",
    "degree in economics from the Wharton School of the University of Pennsylvania. He became president of his father Fred Trump's \\\n",
    "real estate business in 1971, where he renamed it The Trump Organization, and expanded its operations to building or renovating \\\n",
    "skyscrapers, hotels, casinos, and golf courses. Trump later started various side ventures, mostly by licensing his name. Trump\\\n",
    "and his businesses have been involved in more than 4,000 state and federal legal actions, including six bankruptcies. He owned \\\n",
    "the Miss Universe brand of beauty pageants from 1996 to 2015, and produced and hosted the reality television series The \\\n",
    "Apprentice from 2004 to 2015. Trump's political positions have been described as populist, protectionist, isolationist, and\\\n",
    "nationalist. He entered the 2016 presidential race as a Republican and was elected in a surprise Electoral College victory over\\\n",
    "Democratic nominee Hillary Clinton while losing the popular vote.[a] He became the oldest first-term U.S. president[b] and the\\\n",
    "first without prior military or government service. His election and policies have sparked numerous protests. Trump has made\\\n",
    "many false and misleading statements during his campaigns and presidency, to a degree unprecedented in American politics. Many\\\n",
    "of his comments and actions have been characterized as racially charged or racist. During his presidency, Trump ordered a\\\n",
    "travel ban on citizens from several Muslim-majority countries, citing security concerns; after legal challenges, the Supreme\\\n",
    "Court upheld the policy's third revision. He enacted a tax-cut package for individuals and businesses, rescinding the\\\n",
    "individual health insurance mandate penalty of the Affordable Care Act (ACA), but has failed to repeal and replace the ACA as\\\n",
    "a whole. He appointed Neil Gorsuch, Brett Kavanaugh and Amy Coney Barrett to the Supreme Court. In foreign policy, Trump has\\\n",
    "pursued an America First agenda, renegotiating the North American Free Trade Agreement (NAFTA) as the United\\\n",
    "States–Mexico–Canada Agreement (USMCA) and withdrawing the U.S. from the Trans-Pacific Partnership trade negotiations, the\\\n",
    "Paris Agreement on climate change, and the Iran nuclear deal. He imposed import tariffs which triggered a trade war with China,\\\n",
    "moved the U.S. embassy in Israel to Jerusalem, and withdrew U.S. troops from northern Syria. He met three times with North\\\n",
    "Korean leader Kim Jong-un, but talks on denuclearization broke down in 2019. He reacted slowly to the COVID-19 pandemic,\\\n",
    "downplayed the threat, ignored or contradicted many recommendations from health officials, and promoted false information\\\n",
    "about unproven treatments and the availability of testing. A special counsel investigation led by Robert Mueller found\\\n",
    "that Trump and his campaign benefited from Russian interference in the 2016 presidential election, but did not find sufficient\\\n",
    "evidence to press charges of criminal conspiracy or coordination with Russia.[c] Mueller also investigated Trump for\\\n",
    "obstruction of justice, and his report neither indicted nor exonerated Trump on that offense. Trump later pardoned five people\\\n",
    "who were convicted as a result of the Russia investigation. After Trump solicited Ukraine to investigate his political\\\n",
    "rival Joe Biden, the House of Representatives impeached him in December 2019 for abuse of power and obstruction of Congress.\\\n",
    "The Senate acquitted him of both charges in February 2020. Trump lost the 2020 presidential election to Biden but refused to\\\n",
    "concede defeat. He made unsubstantiated accusations of electoral fraud, mounted a series of unsuccessful legal challenges to\\\n",
    "the results, and ordered government officials not to cooperate in the presidential transition.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "Text summary\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "He made unsubstantiated accusations of electoral fraud, mounted a series of unsuccessful legal challenges tothe results, and ordered government officials not to cooperate in the presidential transition. During his presidency, Trump ordered atravel ban on citizens from several Muslim-majority countries, citing security concerns; after legal challenges, the SupremeCourt upheld the policy's third revision.\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "Text category: Politic\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summerize_category(test_3, 2, en_ridge_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(en_ridge_model, open('en_ridge_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test:  0.9316909294512878\n"
     ]
    }
   ],
   "source": [
    "ar_ridge_model = fit_model('ridge_model', True)\n",
    "pickle.dump(ar_ridge_model, open('ar_ridge_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test:  0.8723404255319149\n"
     ]
    }
   ],
   "source": [
    "ar_random_forest_model = fit_model('random_forest_model', True)\n",
    "pickle.dump(ar_random_forest_model, open('ar_random_forest_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ar_logistic_regression_model \u001b[39m=\u001b[39m fit_model(\u001b[39m'\u001b[39;49m\u001b[39mlogistic_regression_model\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      2\u001b[0m pickle\u001b[39m.\u001b[39mdump(ar_logistic_regression_model, \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mar_logistic_regression_model.pkl\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m))\n",
      "Cell \u001b[0;32mIn[22], line 15\u001b[0m, in \u001b[0;36mfit_model\u001b[0;34m(model_name, ar_text)\u001b[0m\n\u001b[1;32m     13\u001b[0m     model_name \u001b[39m=\u001b[39m GaussianNB()\n\u001b[1;32m     14\u001b[0m \u001b[39mif\u001b[39;00m ar_text:\n\u001b[0;32m---> 15\u001b[0m     model_name\u001b[39m.\u001b[39;49mfit(ar_features_train\u001b[39m.\u001b[39;49mtoarray(), ar_y_train)\n\u001b[1;32m     16\u001b[0m     model_predictions \u001b[39m=\u001b[39m model_name\u001b[39m.\u001b[39mpredict(ar_features_test\u001b[39m.\u001b[39mtoarray())\n\u001b[1;32m     17\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAccuracy on test: \u001b[39m\u001b[39m\"\u001b[39m, accuracy_score(ar_y_test, model_predictions))\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/sklearn/linear_model/_logistic.py:1407\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1406\u001b[0m     prefer \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mprocesses\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m-> 1407\u001b[0m fold_coefs_ \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m   1408\u001b[0m                        \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_joblib_parallel_args(prefer\u001b[39m=\u001b[39;49mprefer))(\n\u001b[1;32m   1409\u001b[0m     path_func(X, y, pos_class\u001b[39m=\u001b[39;49mclass_, Cs\u001b[39m=\u001b[39;49m[C_],\n\u001b[1;32m   1410\u001b[0m               l1_ratio\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ml1_ratio, fit_intercept\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_intercept,\n\u001b[1;32m   1411\u001b[0m               tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose, solver\u001b[39m=\u001b[39;49msolver,\n\u001b[1;32m   1412\u001b[0m               multi_class\u001b[39m=\u001b[39;49mmulti_class, max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[1;32m   1413\u001b[0m               class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1414\u001b[0m               random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state, coef\u001b[39m=\u001b[39;49mwarm_start_coef_,\n\u001b[1;32m   1415\u001b[0m               penalty\u001b[39m=\u001b[39;49mpenalty, max_squared_sum\u001b[39m=\u001b[39;49mmax_squared_sum,\n\u001b[1;32m   1416\u001b[0m               sample_weight\u001b[39m=\u001b[39;49msample_weight)\n\u001b[1;32m   1417\u001b[0m     \u001b[39mfor\u001b[39;49;00m class_, warm_start_coef_ \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(classes_, warm_start_coef))\n\u001b[1;32m   1419\u001b[0m fold_coefs_, _, n_iter_ \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mfold_coefs_)\n\u001b[1;32m   1420\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(n_iter_, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32)[:, \u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/joblib/parallel.py:1048\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1040\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1047\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1048\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1049\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/joblib/parallel.py:866\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    864\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    865\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 866\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    867\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/joblib/parallel.py:784\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    783\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 784\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    785\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    788\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    789\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/sklearn/linear_model/_logistic.py:757\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[39mif\u001b[39;00m solver \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mlbfgs\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    755\u001b[0m     iprint \u001b[39m=\u001b[39m [\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m50\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m100\u001b[39m, \u001b[39m101\u001b[39m][\n\u001b[1;32m    756\u001b[0m         np\u001b[39m.\u001b[39msearchsorted(np\u001b[39m.\u001b[39marray([\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m]), verbose)]\n\u001b[0;32m--> 757\u001b[0m     opt_res \u001b[39m=\u001b[39m optimize\u001b[39m.\u001b[39;49mminimize(\n\u001b[1;32m    758\u001b[0m         func, w0, method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mL-BFGS-B\u001b[39;49m\u001b[39m\"\u001b[39;49m, jac\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    759\u001b[0m         args\u001b[39m=\u001b[39;49m(X, target, \u001b[39m1.\u001b[39;49m \u001b[39m/\u001b[39;49m C, sample_weight),\n\u001b[1;32m    760\u001b[0m         options\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39miprint\u001b[39;49m\u001b[39m\"\u001b[39;49m: iprint, \u001b[39m\"\u001b[39;49m\u001b[39mgtol\u001b[39;49m\u001b[39m\"\u001b[39;49m: tol, \u001b[39m\"\u001b[39;49m\u001b[39mmaxiter\u001b[39;49m\u001b[39m\"\u001b[39;49m: max_iter}\n\u001b[1;32m    761\u001b[0m     )\n\u001b[1;32m    762\u001b[0m     n_iter_i \u001b[39m=\u001b[39m _check_optimize_result(\n\u001b[1;32m    763\u001b[0m         solver, opt_res, max_iter,\n\u001b[1;32m    764\u001b[0m         extra_warning_msg\u001b[39m=\u001b[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n\u001b[1;32m    765\u001b[0m     w0, loss \u001b[39m=\u001b[39m opt_res\u001b[39m.\u001b[39mx, opt_res\u001b[39m.\u001b[39mfun\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/scipy/optimize/_minimize.py:681\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    678\u001b[0m     res \u001b[39m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    679\u001b[0m                              \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[1;32m    680\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39ml-bfgs-b\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 681\u001b[0m     res \u001b[39m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[1;32m    682\u001b[0m                            callback\u001b[39m=\u001b[39;49mcallback, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n\u001b[1;32m    683\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtnc\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    684\u001b[0m     res \u001b[39m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[39m=\u001b[39mcallback,\n\u001b[1;32m    685\u001b[0m                         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/scipy/optimize/_lbfgsb_py.py:362\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    356\u001b[0m task_str \u001b[39m=\u001b[39m task\u001b[39m.\u001b[39mtobytes()\n\u001b[1;32m    357\u001b[0m \u001b[39mif\u001b[39;00m task_str\u001b[39m.\u001b[39mstartswith(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFG\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    358\u001b[0m     \u001b[39m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    359\u001b[0m     \u001b[39m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    360\u001b[0m     \u001b[39m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    361\u001b[0m     \u001b[39m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 362\u001b[0m     f, g \u001b[39m=\u001b[39m func_and_grad(x)\n\u001b[1;32m    363\u001b[0m \u001b[39melif\u001b[39;00m task_str\u001b[39m.\u001b[39mstartswith(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNEW_X\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    364\u001b[0m     \u001b[39m# new iteration\u001b[39;00m\n\u001b[1;32m    365\u001b[0m     n_iterations \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/scipy/optimize/_differentiable_functions.py:285\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39marray_equal(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx):\n\u001b[1;32m    284\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m--> 285\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun()\n\u001b[1;32m    286\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_grad()\n\u001b[1;32m    287\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/scipy/optimize/_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_fun\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    250\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated:\n\u001b[0;32m--> 251\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun_impl()\n\u001b[1;32m    252\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/scipy/optimize/_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_fun\u001b[39m():\n\u001b[0;32m--> 155\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m fun_wrapped(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnfev \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[39m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[39m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m fx \u001b[39m=\u001b[39m fun(np\u001b[39m.\u001b[39;49mcopy(x), \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    138\u001b[0m \u001b[39m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/scipy/optimize/_optimize.py:76\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x, \u001b[39m*\u001b[39margs):\n\u001b[1;32m     75\u001b[0m     \u001b[39m\"\"\" returns the the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_if_needed(x, \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m     77\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/scipy/optimize/_optimize.py:70\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39mall(x \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjac \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(x)\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m---> 70\u001b[0m     fg \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfun(x, \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m     71\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjac \u001b[39m=\u001b[39m fg[\u001b[39m1\u001b[39m]\n\u001b[1;32m     72\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value \u001b[39m=\u001b[39m fg[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/sklearn/linear_model/_logistic.py:735\u001b[0m, in \u001b[0;36m_logistic_regression_path.<locals>.func\u001b[0;34m(x, *args)\u001b[0m\n\u001b[0;32m--> 735\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfunc\u001b[39m(x, \u001b[39m*\u001b[39margs): \u001b[39mreturn\u001b[39;00m _multinomial_loss_grad(x, \u001b[39m*\u001b[39;49margs)[\u001b[39m0\u001b[39m:\u001b[39m2\u001b[39m]\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/sklearn/linear_model/_logistic.py:347\u001b[0m, in \u001b[0;36m_multinomial_loss_grad\u001b[0;34m(w, X, Y, alpha, sample_weight)\u001b[0m\n\u001b[1;32m    344\u001b[0m fit_intercept \u001b[39m=\u001b[39m (w\u001b[39m.\u001b[39msize \u001b[39m==\u001b[39m n_classes \u001b[39m*\u001b[39m (n_features \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m))\n\u001b[1;32m    345\u001b[0m grad \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((n_classes, n_features \u001b[39m+\u001b[39m \u001b[39mbool\u001b[39m(fit_intercept)),\n\u001b[1;32m    346\u001b[0m                 dtype\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m--> 347\u001b[0m loss, p, w \u001b[39m=\u001b[39m _multinomial_loss(w, X, Y, alpha, sample_weight)\n\u001b[1;32m    348\u001b[0m sample_weight \u001b[39m=\u001b[39m sample_weight[:, np\u001b[39m.\u001b[39mnewaxis]\n\u001b[1;32m    349\u001b[0m diff \u001b[39m=\u001b[39m sample_weight \u001b[39m*\u001b[39m (p \u001b[39m-\u001b[39m Y)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/sklearn/linear_model/_logistic.py:299\u001b[0m, in \u001b[0;36m_multinomial_loss\u001b[0;34m(w, X, Y, alpha, sample_weight)\u001b[0m\n\u001b[1;32m    297\u001b[0m p \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m logsumexp(p, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[:, np\u001b[39m.\u001b[39mnewaxis]\n\u001b[1;32m    298\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m(sample_weight \u001b[39m*\u001b[39m Y \u001b[39m*\u001b[39m p)\u001b[39m.\u001b[39msum()\n\u001b[0;32m--> 299\u001b[0m loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m alpha \u001b[39m*\u001b[39m squared_norm(w)\n\u001b[1;32m    300\u001b[0m p \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexp(p, p)\n\u001b[1;32m    301\u001b[0m \u001b[39mreturn\u001b[39;00m loss, p, w\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/sklearn/utils/extmath.py:47\u001b[0m, in \u001b[0;36msquared_norm\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(x\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39minteger):\n\u001b[1;32m     44\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m'\u001b[39m\u001b[39mArray type is integer, np.dot may overflow. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     45\u001b[0m                   \u001b[39m'\u001b[39m\u001b[39mData should be float type to avoid this issue\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     46\u001b[0m                   \u001b[39mUserWarning\u001b[39;00m)\n\u001b[0;32m---> 47\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49mdot(x, x)\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ar_logistic_regression_model = fit_model('logistic_regression_model', True)\n",
    "pickle.dump(ar_logistic_regression_model, open('ar_logistic_regression_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test:  0.3045912653975364\n"
     ]
    }
   ],
   "source": [
    "ar_kneighbors_model = fit_model('kneighbors_model', True)\n",
    "pickle.dump(ar_kneighbors_model, open('ar_kneighbors_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test:  0.8096304591265397\n"
     ]
    }
   ],
   "source": [
    "ar_decision_tree_model = fit_model('decision_tree_model', True)\n",
    "pickle.dump(ar_decision_tree_model, open('ar_decision_tree_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test:  0.8824188129899216\n"
     ]
    }
   ],
   "source": [
    "ar_gaussian_nb_model = fit_model('gaussian_nb_model', True)\n",
    "pickle.dump(ar_gaussian_nb_model, open('ar_gaussian_nb_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_test_1 = \"التكنولوجيا هي كلمة ليست عربية ولكن لها مرادف معرب,\\\n",
    "أقترحه مجمع اللغة العربية بدمشق, واعتمدته الجامعة العربية وبعض الدول العربية, ولكن ليس كلها. و هي كلمة شائعة لها أكثر من مصطلح فالتكنولوجيا \\\n",
    "هي علم تطبيقي يهتم بدراسة الإضافات والتطور في العديد من المجالات مثل الصناعات و الفنون والحرف وكل ما يتعلق بها من مواد ووسائل مستعمل.\\\n",
    "والمفهوم الشّائع لمصطلح التّكنولوجيا هو استعمال الكمبيوتر والأجهزة الحديثة، \\\n",
    "وهذه النّظرة محدودة الرؤية ، فالكمبيوتر نتيجة من نتائج التكنولوجيا، بينما التكنولوجيا الّتي يقصدها هذا المقرّر هي طريقة للتّفكير، وحلّ المشكلات، وهي أسلوب التّفكير الّذي\\\n",
    "يوصل الفرد إلى النتائج المرجوّة أي إنّها وسيلة وليست نتيجة، وإنّها طريقة التّفكير في استخدام المعارف، والمعلومات، والمهارات، بهدف الوصول إلى نتائج لإشباع حاجة الإنسان وزيادة قدراته.\\\n",
    " أوّل فائدة تستحقّ الذكر هي ما أسهمت بهِ الثورة العلميّة والتكنولوجيّة في مجال مٌكافحة الأمراض، وتطوير المضادّات الحيوية وهو ما يُدعى بالتكنولوجيا الطبيّة الحيويّة، وأيضاُ مساهمة الأجهزة\\\n",
    " الطبيّة الحديثة في مجالات تخطيط القلب والتصوير الإشعاعي في تشخيص الأمراض، والوصول إلى نتائج مُذهلة في هذا النطاق، أضِف إلى ذلك إدخال التكنولوجيا في إجراء العمليّات الجراحيةّ\\\n",
    " المعقّدة والدقيقة والجراحة بالمنظار والقسطرة، وكذلك تكنولوجيا صناعة الدواء مما ساعدَ كثيراً في شفاء الحالات المُستعصيّة، وتسهيل العمل على الطاقم البشري من أطبّاء وممرضين وصيادلة.\\\n",
    " كما نذكُر فائدة التكنولوجيا في التسهيل على الناس في التنقّل من خلال وسائل النقل والمواصلات الحديثة؛ كظهُور القطارات الكهربائية، والطائرات، وأنظمة النقل البحريّ المتطوّرة.\\\n",
    " وأيضا تساعد التكنولوجيا علي تسهيل مهامّ البحث العلميّ والوصول إلى المعلومة بأقصر وقت وأقلّ تكلفة من السابق؛ حيث توفّر شبكة الإنترنت.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "Text summary\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "التكنولوجيا هي كلمة ليست عربية ولكن لها مرادف معرب,أقترحه مجمع اللغة العربية بدمشق, واعتمدته الجامعة العربية وبعض الدول العربية, ولكن ليس كلها.\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "Text category: Diverse News\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summerize_category(ar_test_1, 1, ar_ridge_model, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_test_2 = \"مع تبوأ بيب غوارديولا دفة الإدارة الفنية لبرشلونة تغيرت أمور كثيرة في الفريق سواء بانضباط اللاعبين أو بأدائهم داخل الملعب. خلال عامه الأول مع برشلونة حقق غوارديولا ما لم يحققه أي مدرب في العالم، ففي تاريخ 2 مايو عام 2009، خاض برشلونة مبارة الكلاسيكو مع غريمه التقليدي ريال مدريد في معقل الأخير، ملعب سانتياغو برنابيو، وحقق برشلونة حينها انتصارًا مدويًا، ففاز بنتيجة 6-2. ضمنت تلك النتيجة إلى حد كبير فوز برشلونة بلقب الليغا، وبعدها بأسبوعين التقى برشلونة مع أتلتيك بلباو في نهائي كأس إسبانيا، وحقق برشلونة اللقب الذي كان غائبا عن خزائنه مدة 13 عامًا، وفي أواخر ذات الشهر حقق برشلونة لقب دوري أبطال أوروبا على حساب نادي مانشستر يونايتد الإنجليزي، وليكون ذلك اللقب الثالث للنادي بتلك البطولة. في شهر أغسطس من ذلك العام ظفر برشلونة ببطولتي كأس السوبر الإسباني على حساب أتلتيك بيلباو للمرة الثامنة بتاريخه وبطولة كأس السوبر الأوروبي على حساب نادي شاختار دونستيك الأوكراني، وفي أواخر العام ذاته شارك النادي كممثل لقارة أوروبا في بطولة كأس العالم لأندية كرة القدم محققًا لقبها لأول مرة في تاريخه بعد انتصاره في المباراة النهائية على نادي إستوديانتيس دو لا بلاتا الأرجنتيني في نهائي مثير امتد لشوطين إضافيين، ليسدل الفريق الستار عن ذلك العام الاستثنائي بإنجاز غير مسبوق، بلغ 6 ألقاب بعام واحد، ويعرف باسم السداسية التاريخية. من أهم النجوم خلال ذلك العام: ليونيل ميسي، تشافي هيرنانديز، أندريس إنيستا رغم أن الغلة خلال عام 2010 لم تكن كسابقتها إلا أن الإبداع والأداء الراقي ظل مستمرًا. أبرز ما حدث في ذلك العام من انجازات كان الظفر ببطولة الليغا للمرة العشرين بتاريخ النادي، وكأس السوبر الإسباني للمرة التاسعة، وخروج برشلونة من دوري أبطال أوروبا أمام إنتر ميلان الإيطالي من الدور نصف النهائي، وخرج كذلك مبكرًا من كأس الملك أمام نادي إشبيلية. أما على صعيد الانتقالات، فقد غادر خلال صيف ذلك العام الفرنسي تيري هنري، وسبقه في الرحيل الكميروني صامويل ايتو في صفقة مبادلة مع نادي الانتر الإيطالي أتى بموجبها اللاعب السويدي إبراهيموفيتش في صفقة تعد الأكبر بتاريخ النادي. لم يمكث ابراهيموفيتش سوى عام واحد أعير بعده إلى لنادي ميلان الإيطالي، وضُم المهاجم الإسباني دافيد فيا من نادي فالنسيا خلال صيف عام 2010. إداريًا فقد جرت انتخابات رئاسة للنادي، وصل على أثرها ساندرو روسيل لرئاسة النادي خلفًا للمحامي خوان لابورتا. في افتتاحية موسم 2010-2011 حقق النادي لقب كأس السوبر الإسباني للمرة التاسعة في تاريخه، وشهد ذات الموسم صراعًا محتدمًا بين برشلونة وغريمه ريال مدريد، ولم يقتصر هذا الصراع على بطولة الليغا، التي حافظ عليها الفريق للمرة الثالثة على التوالي والحادية والعشرين في تاريخ النادي، إذ امتد الصراع ليشمل بطولتي كأس الملك ودوري أبطال أوروبا. وصل برشلونة المباراة النهائية ببطولة كأس إسبانيا ليلتقي الريال الذي استطاع خطف هدف الفوز بالوقت الإضافي الأول، وبعد تلك المباراة بأقل من أسبوع التقى برشلونة مجددًا مع ريال مدريد في الدور نصف النهائي لبطولة دوري أبطال أوروبا واستطاع برشلونة الإطاحة بريال مدريد والوصول للمباراة النهائية بتلك البطولة، والتي جمعت برشلونة مع نادي مانشستر يونايتد الإنجليزي، على ملعب ويمبلي في العاصمة البريطانية لندن، انتصر على إثرها فريق المدرب بيب غوارديولا بنتيجة 3-1 بعد أداء خيالي لنجوم الفريق في المباراة النهائية، محققين اللقب الرابع للكتلان بتلك البطولة، ومحققين أيضًا رقما قياسيا في عدد مرات الوصول لمبارة نهائية في إطار بطولات الأندية الأوروبية. لم تتوقف إنجازات النادي خلال عام 2011 عند ذلك، ففي مستهل الموسم الكروي 2011- 2012 وتحديدًا في منتصف شهر أغسطس، فاز النادي بكأس السوبر الإسباني عندما تفوق على غريمة التقليدي فريق ريال مدريد، ولم يمض أسبوع بعد تحقيق لقب تلك البطولة حتى حقق النادي كأس السوبر الأوروبي على حساب نادي بورتو البرتغالي، لتزداد غلة النادي من الألقاب ويصبح جوسيب غوارديولا أنجح مدرب في تاريخ النادي من حيث عدد الألقاب، وفي أواخر عام 2011 شارك النادي ببطولة كأس العالم للأندية في اليابان وتمكن من الظفر بلقب تلك البطولة بعد تفوقة في المباراة النهائية على فريق سانتوس البرازيلي\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "Text summary\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "لم يمكث ابراهيموفيتش سوى عام واحد أعير بعده إلى لنادي ميلان الإيطالي، وضُم المهاجم الإسباني دافيد فيا من نادي فالنسيا خلال صيف عام 2010. من أهم النجوم خلال ذلك العام: ليونيل ميسي، تشافي هيرنانديز، أندريس إنيستا رغم أن الغلة خلال عام 2010 لم تكن كسابقتها إلا أن الإبداع والأداء الراقي ظل مستمرًا. إداريًا فقد جرت انتخابات رئاسة للنادي، وصل على أثرها ساندرو روسيل لرئاسة النادي خلفًا للمحامي خوان لابورتا. مع تبوأ بيب غوارديولا دفة الإدارة الفنية لبرشلونة تغيرت أمور كثيرة في الفريق سواء بانضباط اللاعبين أو بأدائهم داخل الملعب.\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n",
      "Text category: Sport\n",
      "-------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summerize_category(ar_test_2, 6, ar_ridge_model, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
